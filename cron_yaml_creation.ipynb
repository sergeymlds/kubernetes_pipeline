{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YandexCloud init\n",
    "\n",
    "ya_service_name = 's3'\n",
    "ya_url = os.environ['ya_url']\n",
    "ya_key_id = os.environ['ya_key_id']\n",
    "ya_key = os.environ['ya_key']\n",
    "container_name = os.environ['container_name']\n",
    "\n",
    "session = boto3.session.Session()\n",
    "s3 = session.client(\n",
    "    service_name=ya_service_name,\n",
    "    endpoint_url=ya_url,\n",
    "    aws_access_key_id = ya_key_id,\n",
    "    aws_secret_access_key = ya_key\n",
    "    )\n",
    "\n",
    "\n",
    "def reader_csv(container_name, key_name, is_header=True):\n",
    "    '''\n",
    "        Get data from storage for a single operation:\n",
    "          container_name -- str, container name in storage\n",
    "          key_name -- str, way to data in storage\n",
    "          is_header -- bool, if TRUE header in data exist, FALSE header=None\n",
    "        Return: DataFrame\n",
    "    '''\n",
    "    response = s3.get_object(Bucket=container_name, \n",
    "                             Key=key_name)\n",
    "    if is_header:\n",
    "        df = pd.read_csv(response.get(\"Body\"))\n",
    "    else:\n",
    "        df = pd.read_csv(response.get(\"Body\"), header=None)\n",
    "    return df\n",
    "\n",
    "\n",
    "# read all switch stores\n",
    "switch_on = reader_csv('spardata', r'switch_on/stores.csv', is_header=True)  \n",
    "stores = switch_on['ObjCode'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WF config\n",
    "ram_need = 14\n",
    "ram_up_limit = 18\n",
    "nodes = 12 # VMs count for the task \n",
    "\n",
    "minutes = 0\n",
    "hours = 0\n",
    "month_day = '*'    # every\n",
    "month = '*'        # every\n",
    "day_of_week = '*'  # every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_list = []\n",
    "\n",
    "for i in range(nodes):\n",
    "    stores_list.append([]) \n",
    "\n",
    "for i in range(len(stores)):\n",
    "    k = i%nodes\n",
    "    stores_list[k].append(stores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# templates\n",
    "resources = f\"\"\"\n",
    "                  resources:\n",
    "                      requests:\n",
    "                          memory: {ram_need}Gi\n",
    "                      limits:\n",
    "                          memory: {ram_up_limit}Gi\"\"\"\n",
    "\n",
    "head = \"\"\"apiVersion: argoproj.io/v1alpha1\n",
    "kind: CronWorkflow\n",
    "metadata:\n",
    "    name: cron-dag-spar-wf\n",
    "spec:\n",
    "    schedule: \"{}\"\n",
    "    concurrencyPolicy: \"Replace\"\n",
    "    startingDeadlineSeconds: 0\n",
    "    workflowSpec:\n",
    "        entrypoint: prediction-pipeline\n",
    "        templates:\n",
    "            - name: prediction-pipeline\n",
    "              dag:\n",
    "                tasks:\n",
    "\n",
    "                - name: prep\n",
    "                  template: python-preparing-script\"\"\"\n",
    "\n",
    "dag_disc_update = \"\"\"\n",
    "                - name: disc-update{}\n",
    "                  dependencies: [prep]\n",
    "                  template: python-disc-updating-script{}\"\"\"\n",
    "\n",
    "dag_pred = \"\"\"\n",
    "                - name: prediction{}\n",
    "                  dependencies: [disc-update{}]\n",
    "                  template: python-prediction-script{}\"\"\"\n",
    "\n",
    "dag_promo_delete_temp = \"\"\"\n",
    "                - name: temp-promo-delete\n",
    "                  dependencies: [{}]\n",
    "                  template: python-temp-promo-del-script\"\"\"\n",
    "\n",
    "prep_image_run = \"\"\"\n",
    "            - name: python-preparing-script          \n",
    "              script:\n",
    "                  image: cr.yandex/crp479pqesbl9eqd05c2/preparing:latest\n",
    "                  command: [bash]\n",
    "                  source: |\n",
    "                      python preparing.py\"\"\" + resources\n",
    "    \n",
    "disc_update_image_run = \"\"\"\n",
    "            - name: python-disc-updating-script{}\n",
    "              script:\n",
    "                  image: cr.yandex/crp479pqesbl9eqd05c2/discount_updating:latest\n",
    "                  command: [bash]\n",
    "                  source: |\n",
    "                      python discount_updating.py --stores '{}'\"\"\" + resources\n",
    "\n",
    "\n",
    "pred_image_run = \"\"\"\n",
    "            - name: python-prediction-script{}\n",
    "              script:\n",
    "                  image: cr.yandex/crp479pqesbl9eqd05c2/prediction:latest\n",
    "                  command: [bash]\n",
    "                  source: |\n",
    "                      python prediction1.py --stores '{}'\"\"\" + resources\n",
    "\n",
    "promo_delete_image_run = \"\"\"\n",
    "            - name: python-temp-promo-del-script\n",
    "              script:\n",
    "                  image: cr.yandex/crp479pqesbl9eqd05c2/temp_promo_deleting:latest\n",
    "                  command: [bash]\n",
    "                  source: |\n",
    "                      python temp_promo_deleting.py\"\"\" + resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_images_run = []\n",
    "pred_images_run = []\n",
    "full_dag_disc_update = []\n",
    "full_dag_prediction = []\n",
    "all_pred_dags = []\n",
    "\n",
    "for num_batch, batch_stores in enumerate(stores_list):\n",
    "    full_dag_disc_update += [dag_disc_update.format(*[str(num_batch)]*2)]\n",
    "    full_dag_prediction += [dag_pred.format(*[str(num_batch)]*3)]\n",
    "\n",
    "    disc_images_run += [disc_update_image_run.format(num_batch, ','.join(list(map(str, batch_stores))))]\n",
    "    pred_images_run += [pred_image_run.format(num_batch, ','.join(list(map(str, batch_stores))))]\n",
    "    all_pred_dags += [f'prediction{num_batch}']\n",
    "    \n",
    "full_dag_disc_update = '\\n'.join(full_dag_disc_update)\n",
    "full_dag_prediction = '\\n'.join(full_dag_prediction)\n",
    "\n",
    "all_pred_dags = ','.join(all_pred_dags)\n",
    "full_dag_promo_delete_temp = dag_promo_delete_temp.format(all_pred_dags)\n",
    "\n",
    "disc_images_run = '\\n'.join(disc_images_run)\n",
    "pred_images_run = '\\n'.join(pred_images_run)\n",
    "\n",
    "dag_final = (head + '\\n' + full_dag_disc_update + '\\n' + full_dag_prediction + '\\n' + full_dag_promo_delete_temp + '\\n\\n' + \n",
    "             prep_image_run + '\\n' + disc_images_run + '\\n' + pred_images_run + '\\n' + promo_delete_image_run)\n",
    "\n",
    "dag_final = (head.format(f'{minutes} {hours} {month_day} {month} {day_of_week}') + '\\n' +\n",
    "             full_dag_disc_update + '\\n' + full_dag_prediction + '\\n' + full_dag_promo_delete_temp + '\\n\\n' + \n",
    "             prep_image_run + '\\n' + disc_images_run + '\\n' + pred_images_run + '\\n' + promo_delete_image_run)\n",
    "\n",
    "f = open(\"cron_dag_final.yaml\", \"w\")\n",
    "f.write(dag_final)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
